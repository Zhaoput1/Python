{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "tfds.disable_progress_bar()\n",
    "import collections\n",
    "import pathlib\n",
    "import re\n",
    "import string\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import preprocessing\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_text as tf_text\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfds.disable_progress_bar()\n",
    "\n",
    "def plot_graphs(history, metric):   #define a function to plot the history graph with accuracy and loss\n",
    "    plt.plot(history.history[metric])\n",
    "    plt.plot(history.history['val_'+metric], '')\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(metric)\n",
    "    plt.legend([metric, 'val_'+metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 files belonging to 10 classes.\n",
      "Using 800 files for training.\n"
     ]
    }
   ],
   "source": [
    "#batch_size = 32\n",
    "seed = 42 #set seed\n",
    "\n",
    "train_dataset = preprocessing.text_dataset_from_directory( #separate the dataset to training dataset and test dataset\n",
    "    'archive',\n",
    "#    batch_size=batch_size,\n",
    "    validation_split=0.2,\n",
    "    subset='training',\n",
    "    seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 files belonging to 10 classes.\n",
      "Using 200 files for validation.\n"
     ]
    }
   ],
   "source": [
    "test_dataset = preprocessing.text_dataset_from_directory(\n",
    "    'archive',\n",
    "#    batch_size=batch_size,\n",
    "    validation_split=.2,\n",
    "    subset='validation',\n",
    "    seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE=5000   #set the size of the vocabulary lab \n",
    "#The raw text loaded by tfds needs to be processed before it can be used in a model. \n",
    "encoder = tf.keras.layers.experimental.preprocessing.TextVectorization( # experimental preprocessing\n",
    "    max_tokens=VOCAB_SIZE)\n",
    "encoder.adapt(train_dataset.map(lambda text, label: text)) #Create the layer, and pass the dataset's text to the layer's .adapt method\n",
    "vocab = np.array(encoder.get_vocabulary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([ #build the sequential\n",
    "    encoder,  #first encoder layer defined above\n",
    "    tf.keras.layers.Embedding(  # with 64 dim output\n",
    "        input_dim=len(encoder.get_vocabulary()),\n",
    "        output_dim=64,\n",
    "        # Use masking to handle the variable sequence lengths\n",
    "        mask_zero=True),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)), #LSTM 64 dims\n",
    "    tf.keras.layers.Dense(64, activation='relu'),#64 cells with relu activation function\n",
    "    tf.keras.layers.Dense(10, activation='softmax') #5 dim output with softmax activation function\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', # loss function \n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),  #optimizer with learning rate .001\n",
    "              metrics=['accuracy']) # metrics set to be accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystopping_cb = keras.callbacks.EarlyStopping (patience=10, restore_best_weights=True) # set callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "25/25 [==============================] - 42s 2s/step - loss: 2.2941 - accuracy: 0.1663 - val_loss: 2.2780 - val_accuracy: 0.2375\n",
      "Epoch 2/50\n",
      "24/25 [===========================>..] - ETA: 1s - loss: 2.1512 - accuracy: 0.3763"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_dataset, epochs=50,  #training process epochs=50\n",
    "                    validation_data=test_dataset, \n",
    "                    validation_steps=5,\n",
    "                    callbacks=earlystopping_cb) #set callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_dataset)  #result evaluation \n",
    "\n",
    "print('Test Loss: {}'.format(test_loss))\n",
    "print('Test Accuracy: {}'.format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8)) \n",
    "plt.subplot(1,2,1)\n",
    "plot_graphs(history, 'accuracy')\n",
    "plt.ylim(None,1)\n",
    "plt.subplot(1,2,2)\n",
    "plot_graphs(history, 'loss')\n",
    "plt.ylim(0,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
