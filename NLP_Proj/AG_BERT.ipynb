{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_E60C-KtFOsE",
    "outputId": "1d7c8664-faed-486f-d63c-c69a5eb53719"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openjdk version \"1.8.0_275\"\n",
      "OpenJDK Runtime Environment (build 1.8.0_275-8u275-b01-0ubuntu1~18.04-b01)\n",
      "OpenJDK 64-Bit Server VM (build 25.275-b01, mixed mode)\n",
      "Collecting pyspark==2.4.4\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/21/f05c186f4ddb01d15d0ddc36ef4b7e3cedbeb6412274a41f26b55a650ee5/pyspark-2.4.4.tar.gz (215.7MB)\n",
      "\u001b[K     |████████████████████████████████| 215.7MB 66kB/s \n",
      "\u001b[?25hCollecting py4j==0.10.7\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/53/c737818eb9a7dc32a7cd4f1396e787bd94200c3997c72c1dbe028587bd76/py4j-0.10.7-py2.py3-none-any.whl (197kB)\n",
      "\u001b[K     |████████████████████████████████| 204kB 43.5MB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
      "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pyspark: filename=pyspark-2.4.4-py2.py3-none-any.whl size=216130389 sha256=bc470d47088635587595049280aec48e403937cfde8910b23670f7d2cc442df2\n",
      "  Stored in directory: /root/.cache/pip/wheels/ab/09/4d/0d184230058e654eb1b04467dbc1292f00eaa186544604b471\n",
      "Successfully built pyspark\n",
      "Installing collected packages: py4j, pyspark\n",
      "Successfully installed py4j-0.10.7 pyspark-2.4.4\n",
      "Collecting spark-nlp==2.6.4\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/26/f7a6ac12339d2f1ed271c46c16705665620059e4559f323695925f3c63b4/spark_nlp-2.6.4-py2.py3-none-any.whl (129kB)\n",
      "\u001b[K     |████████████████████████████████| 133kB 5.8MB/s \n",
      "\u001b[?25hInstalling collected packages: spark-nlp\n",
      "Successfully installed spark-nlp-2.6.4\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Install java\n",
    "! apt-get update -qq\n",
    "! apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n",
    "\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\n",
    "! java -version\n",
    "\n",
    "# Install pyspark\n",
    "! pip install --ignore-installed pyspark==2.4.4\n",
    "\n",
    "# Install Spark NLP\n",
    "! pip install --ignore-installed spark-nlp==2.6.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2Hmgp3h8FYwg",
    "outputId": "d219eda8-a899-449f-bd7f-d7daf28a21e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "EVLAxgnKFZn3"
   },
   "outputs": [],
   "source": [
    "import sparknlp \n",
    "\n",
    "spark = sparknlp.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "gwW8rrVjFZqU"
   },
   "outputs": [],
   "source": [
    "df = spark.read.option(\"header\", True).csv('drive/My Drive/news.csv').drop('Title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "5NTHq9EbFZsl"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "# pn_udf = udf(lambda x: [str(x)], ArrayType(StringType()) )\n",
    "pn_udf = udf(lambda x: str(x), StringType())\n",
    "dfl = df.withColumn('label',pn_udf('Class')).drop('Class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5oizreGTFZux",
    "outputId": "b8cd4505-db6e-45e5-9093-b409d9a16005"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+\n",
      "|category|                text|\n",
      "+--------+--------------------+\n",
      "|       3|Reuters - Short-s...|\n",
      "|       3|Reuters - Private...|\n",
      "|       3|Reuters - Soaring...|\n",
      "|       3|Reuters - Authori...|\n",
      "|       3|AFP - Tearaway wo...|\n",
      "+--------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_l = dfl.selectExpr(\"label as category\",\"Description as text\")\n",
    "df_l.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7u4k0MQzqqDu",
    "outputId": "7fd7d307-8261-4150-c415-30afe7505cfb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120000"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_l.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "E551bjmaFZxJ"
   },
   "outputs": [],
   "source": [
    "df_train, df_test = df_l.randomSplit([.7, .3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "vwvz7NIEFZzY"
   },
   "outputs": [],
   "source": [
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "from pyspark.ml import Pipeline\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lBwDEY2LFZ2G",
    "outputId": "80aa4479-0197-47d6-aeb8-d2891acf4d4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert_base_cased download started this may take some time.\n",
      "Approximate size to download 389.1 MB\n",
      "[OK!]\n",
      "tfhub_use download started this may take some time.\n",
      "Approximate size to download 923.7 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "document = DocumentAssembler()\\\n",
    "    .setInputCol(\"text\")\\\n",
    "    .setOutputCol(\"document\")\n",
    "tokenizer = Tokenizer()\\\n",
    "  .setInputCols(['document'])\\\n",
    "  .setOutputCol('token')\n",
    "normalizer = Normalizer()\\\n",
    "  .setInputCols(['token'])\\\n",
    "  .setOutputCol('normalized')\n",
    "stopwords_cleaner = StopWordsCleaner()\\\n",
    "  .setInputCols(['normalized'])\\\n",
    "  .setOutputCol('cleanTokens')\\\n",
    "  .setCaseSensitive(False)\n",
    "\n",
    "word_embeddings = BertEmbeddings\\\n",
    "  .pretrained(\"bert_base_cased\", \"en\")\\\n",
    "  .setInputCols(['document','cleanTokens'])\\\n",
    "  .setOutputCol(\"embeddings\")\\\n",
    "  .setCaseSensitive(False)\n",
    "\n",
    "use = UniversalSentenceEncoder.pretrained() \\\n",
    " .setInputCols([\"document\",\"embeddings\"])\\\n",
    " .setOutputCol(\"sentence_embeddings\")\n",
    "\n",
    "\n",
    "classsifierdl = ClassifierDLApproach()\\\n",
    "  .setInputCols([\"sentence_embeddings\"])\\\n",
    "  .setOutputCol(\"class\")\\\n",
    "  .setLabelColumn(\"category\")\\\n",
    "  .setMaxEpochs(5)\\\n",
    "  .setEnableOutputLogs(True)\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    stages = [\n",
    "        document,\n",
    "        tokenizer,\n",
    "        normalizer,\n",
    "        stopwords_cleaner,\n",
    "        word_embeddings,\n",
    "        use,\n",
    "        classsifierdl\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "-GwmeUSjFZ4t"
   },
   "outputs": [],
   "source": [
    "bert_pipelineModel = pipeline.fit(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "-wzQi77GFZ7B"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "df = bert_pipelineModel.transform(df_test).select('category','text','class.result').toPandas()\n",
    "df['result'] = df['result'].apply(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HAiXiV7AFZ9H",
    "outputId": "ad521378-c612-454a-c865-6f9460d38479"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix is \n",
      "[[7929  276  455  328]\n",
      " [  93 8717   58   70]\n",
      " [ 394   84 7448 1277]\n",
      " [ 292   62  587 8073]]\n",
      "accuracy is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.91      0.88      0.90      8988\n",
      "           2       0.95      0.98      0.96      8938\n",
      "           3       0.87      0.81      0.84      9203\n",
      "           4       0.83      0.90      0.86      9014\n",
      "\n",
      "    accuracy                           0.89     36143\n",
      "   macro avg       0.89      0.89      0.89     36143\n",
      "weighted avg       0.89      0.89      0.89     36143\n",
      "\n",
      "f1 score is:\n",
      "0.8899925296737957\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print('confusion matrix is ')\n",
    "print(confusion_matrix(df.category, df.result))\n",
    "print('accuracy is:')\n",
    "print(classification_report(df.category, df.result))\n",
    "print('f1 score is:')\n",
    "print(accuracy_score(df.category, df.result))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "AG_BERT.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
