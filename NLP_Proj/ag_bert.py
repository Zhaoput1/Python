# -*- coding: utf-8 -*-
"""AG_BERT.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1EEsa5pz5j_un34hax_ez0mzKKaLxwaa0
"""

import os

# Install java
! apt-get update -qq
! apt-get install -y openjdk-8-jdk-headless -qq > /dev/null

os.environ["JAVA_HOME"] = "/usr/lib/jvm/java-8-openjdk-amd64"
os.environ["PATH"] = os.environ["JAVA_HOME"] + "/bin:" + os.environ["PATH"]
! java -version

# Install pyspark
! pip install --ignore-installed pyspark==2.4.4

# Install Spark NLP
! pip install --ignore-installed spark-nlp==2.6.4

from google.colab import drive
drive.mount('/content/drive')

import sparknlp 

spark = sparknlp.start()

df = spark.read.option("header", True).csv('drive/My Drive/news.csv').drop('Title')

from pyspark.sql.functions import *
from pyspark.sql.types import *
# pn_udf = udf(lambda x: [str(x)], ArrayType(StringType()) )
pn_udf = udf(lambda x: str(x), StringType())
dfl = df.withColumn('label',pn_udf('Class')).drop('Class')

df_l = dfl.selectExpr("label as category","Description as text")
df_l.show(5)

df_l.count()

df_train, df_test = df_l.randomSplit([.7, .3])

from sparknlp.base import *
from sparknlp.annotator import *
from pyspark.ml import Pipeline
import pandas as pd

document = DocumentAssembler()\
    .setInputCol("text")\
    .setOutputCol("document")
tokenizer = Tokenizer()\
  .setInputCols(['document'])\
  .setOutputCol('token')
normalizer = Normalizer()\
  .setInputCols(['token'])\
  .setOutputCol('normalized')
stopwords_cleaner = StopWordsCleaner()\
  .setInputCols(['normalized'])\
  .setOutputCol('cleanTokens')\
  .setCaseSensitive(False)

word_embeddings = BertEmbeddings\
  .pretrained("bert_base_cased", "en")\
  .setInputCols(['document','cleanTokens'])\
  .setOutputCol("embeddings")\
  .setCaseSensitive(False)

use = UniversalSentenceEncoder.pretrained() \
 .setInputCols(["document","embeddings"])\
 .setOutputCol("sentence_embeddings")


classsifierdl = ClassifierDLApproach()\
  .setInputCols(["sentence_embeddings"])\
  .setOutputCol("class")\
  .setLabelColumn("category")\
  .setMaxEpochs(5)\
  .setEnableOutputLogs(True)

pipeline = Pipeline(
    stages = [
        document,
        tokenizer,
        normalizer,
        stopwords_cleaner,
        word_embeddings,
        use,
        classsifierdl
    ])

bert_pipelineModel = pipeline.fit(df_train)

from sklearn.metrics import classification_report, accuracy_score
df = bert_pipelineModel.transform(df_test).select('category','text','class.result').toPandas()
df['result'] = df['result'].apply(lambda x: x[0])

from sklearn.metrics import confusion_matrix
print('confusion matrix is ')
print(confusion_matrix(df.category, df.result))
print('accuracy is:')
print(classification_report(df.category, df.result))
print('f1 score is:')
print(accuracy_score(df.category, df.result))